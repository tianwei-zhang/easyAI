% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deep_logistic.R
\name{deep_logistic}
\alias{deep_logistic}
\title{Deep Learning Classification with Automated Parameter Tuning}
\usage{
deep_logistic(x, y, num_layer = seq(1, 5, 1), max_units = NULL,
  start_unit = 5, max_dropout = 0.2, min_dropout = 0, max_lr = 0.2,
  min_lr = 0.001, iteration_per_layer = 5, num_epoch = 5,
  num_patience = 3)
}
\arguments{
\item{x}{training feature matrix}

\item{y}{target matrix}

\item{num_layer}{a vector of integers indicating the number of hidden layers to test. Default to seq(1,5,1)}

\item{max_units}{the maximum number of hidden units in a layer. Default to an optimized value based on data}

\item{start_unit}{the minimum number of hiddent units in a layer. Default to 5}

\item{max_dropout}{A number between 0 and 1 indicating the maximum dropoff rate in a layer. Default to 0.2}

\item{min_dropout}{A number between 0 and 1 indicating the minimum dropoff rate in a layer. Default to 0}

\item{max_lr}{maximum learning rate in a run. Default to 0.2}

\item{min_lr}{minimum learning rate in a run. Default to 0.001}

\item{iteration_per_layer}{Number of parameter randomizations for a given number of hidden layers. More iterations will explore a larger parameter space}

\item{num_epoch}{number of epoches to go through during training}

\item{num_patience}{number of patience in early stopping criteria}
}
\value{
returns a list object with two values: 
train_performance: A table with parameters and model performance metrics
best_model: a keras_model object with the optimal parameters
}
\description{
Deep Learning Classification with Automated Parameter Tuning
}
