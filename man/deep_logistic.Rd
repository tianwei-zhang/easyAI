% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deep_logistic.R
\name{deep_logistic}
\alias{deep_logistic}
\title{Deep Learning Classification with Automated Parameter Tuning}
\usage{
deep_logistic(x, y, option, num_layer = seq(1, 3, 1), max_units = NULL,
  start_unit = 5, max_dropout = 0.2, min_dropout = 0, max_lr = 0.2,
  min_lr = 0.001, iteration_per_layer = 10, validation_split = 0.2,
  num_epoch = 10, num_patience = 3, machine_type = "standard")
}
\arguments{
\item{x}{training feature matrix}

\item{y}{target matrix}

\item{option}{either local or google for hyper-parameter tuning}

\item{num_layer}{a vector of integers indicating the number of hidden layers to test. Default to seq(1,3,1)}

\item{max_units}{the maximum number of hidden units in a layer. Default to an optimized value based on data}

\item{start_unit}{the minimum number of hiddent units in a layer. Default to 5}

\item{max_dropout}{A number between 0 and 1 indicating the maximum dropoff rate in a layer. Default to 0.2}

\item{min_dropout}{A number between 0 and 1 indicating the minimum dropoff rate in a layer. Default to 0}

\item{max_lr}{maximum learning rate in a run. Default to 0.2}

\item{min_lr}{minimum learning rate in a run. Default to 0.001}

\item{iteration_per_layer}{Number of parameter randomizations for a given number of hidden layers. More iterations will explore a larger parameter space}

\item{validation_split}{Percent of data used for validation. Default to 20 percent}

\item{num_epoch}{number of epoches to go through during training. Default to 10}

\item{num_patience}{number of patience in early stopping criteria. Default to 3}

\item{machine_type}{type of server to use. Could be standard, standard_gpu, standard_p100. For more visit https://cloud.google.com/ml-engine/docs/training-overview#machine_type_table}
}
\value{
returns a list object with two values: 
\itemize{
  \item{train_performance: A table with parameters and model performance metrics}
  \item{best_model: a keras_model object with the optimal structure}
}
}
\description{
Deep Learning Classification with Automated Parameter Tuning
}
